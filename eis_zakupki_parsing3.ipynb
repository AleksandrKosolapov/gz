{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd078cda-6755-43df-bd86-2dd9f1208aaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def get_next_element(lst, current):\n",
    "    try:\n",
    "        index = lst.index(current)\n",
    "        return lst[index + 1]\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "\n",
    "def clean_text(text): #Очистка текста от лишних пробелов и переносов строк. Заменяем все виды пробельных символов на один пробел\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text(soup): #Извлечение и очистка всего текста со страницы. Извлекаем текст из тела страницы\n",
    "    body = soup.body\n",
    "    if not body:\n",
    "        return \"\"\n",
    "    texts = [clean_text(text) for text in body.stripped_strings] # Получаем все строки текста, очищенные от лишних пробелов\n",
    "    cleaned_text = [text for text in texts if text] # Объединяем их в список, исключая пустые строки\n",
    "    return cleaned_text\n",
    "\n",
    "def extract_links(soup, base_url): #Извлечение всех гиперссылок со страницы\n",
    "    links = []\n",
    "    for link in soup.find_all(\"a\", href=True):\n",
    "        link_text = clean_text(link.get_text())\n",
    "        href = urljoin(base_url, link['href'])  # Преобразуем относительные ссылки в абсолютные\n",
    "        links.append({\"text\": link_text, \"url\": href})\n",
    "    return links\n",
    "\n",
    "def extract_elements(soup): #Извлечение всех элементов со страницы\n",
    "    elements = []\n",
    "    for tag in soup.find_all(True):  # Перебираем все теги\n",
    "        tag_text = clean_text(tag.get_text())\n",
    "        if tag_text:  # Добавляем только если есть текст\n",
    "            elements.append({\"tag\": tag.name,\n",
    "                             \"attributes\": tag.attrs,\n",
    "                             \"text\": tag_text})\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "920c49e4-1c9b-417d-9172-dd5b7b1444e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping for 3 seconds...\n",
      "Ключевое слово: лизинг, Страница: 1\n",
      "Sleeping for 3 seconds...\n",
      "Страница 2 не содержит '№ ', прерываем цикл страниц для ключевого слова 'лизинг'.\n",
      "Завершен обработка ключевого слова: лизинг\n",
      "Sleeping for 5 seconds...\n",
      "Страница 1 не содержит '№ ', прерываем цикл страниц для ключевого слова 'финансовая+аренда'.\n",
      "Завершен обработка ключевого слова: финансовая+аренда\n",
      "Sleeping for 3 seconds...\n",
      "Страница 1 не содержит '№ ', прерываем цикл страниц для ключевого слова 'лизинг'.\n",
      "Завершен обработка ключевого слова: лизинг\n",
      "Sleeping for 3 seconds...\n",
      "Страница 1 не содержит '№ ', прерываем цикл страниц для ключевого слова 'финансовая+аренда'.\n",
      "Завершен обработка ключевого слова: финансовая+аренда\n"
     ]
    }
   ],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"}\n",
    "\n",
    "# Ваши исходные данные\n",
    "publishdate = '29.01.2025' #datetime.now().strftime('%d.%m.%Y')\n",
    "cnt_records = 50\n",
    "keywords = ['лизинг','финансовая+аренда']\n",
    "\n",
    "# Инициализация DataFrame\n",
    "hdf = pd.DataFrame(columns=['№', 'link'])\n",
    "filtered_data = []\n",
    "\n",
    "for fz in [44,223]:\n",
    "    for keyword in keywords:\n",
    "        for page in range(1, 1000):\n",
    "            # Задержка на случайное количество секунд\n",
    "            sleep_time = random.randint(3, 6)\n",
    "            print(f\"Sleeping for {sleep_time} seconds...\")\n",
    "            time.sleep(sleep_time)\n",
    "            \n",
    "            # Формирование URL\n",
    "            if fz == 44:\n",
    "                url = (f\"https://zakupki.gov.ru/epz/orderplan/search/results.html?\"\n",
    "                       f\"searchString={keyword}&morphology=on&structuredCheckBox=on&structured=true&\"\n",
    "                       f\"notStructured=on&fz44=on&planStatusTypes_0=on&planStatusTypes=0&\"\n",
    "                       f\"publishDateFrom={publishdate}&sortBy=BY_MODIFY_DATE&pageNumber={page}&\"\n",
    "                       f\"sortDirection=false&recordsPerPage=_{cnt_records}&showLotsInfoHidden=on&searchType=false\")\n",
    "            if fz == 223:\n",
    "                url = (f\"https://zakupki.gov.ru/epz/orderplan/search/results.html?\"\n",
    "               f\"searchString={keyword}&morphology=on&structuredCheckBox=on&structured=true&\"\n",
    "               f\"notStructuredCheckBox=on&notStructured=true&fz223=on&publishDateFrom={publishdate}&\"\n",
    "               f\"sortBy=BY_MODIFY_DATE&pageNumber={page}&sortDirection=false&recordsPerPage={cnt_records}&showLotsInfoHidden=on&searchType=false\")\n",
    "\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers)\n",
    "                response.raise_for_status()  # Проверка на успешный запрос\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Ошибка при запросе к {url}: {e}\")\n",
    "                break  # Прерываем цикл страницы при ошибке запроса\n",
    "    \n",
    "            # Парсинг HTML\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            raw_text = soup.get_text(separator=\"\\n\")\n",
    "            cleantext = \"\\n\".join([line.strip() for line in raw_text.splitlines() if line.strip()])\n",
    "            data = {\"url\": url, \"page_text\": cleantext, \"links\": []}\n",
    "            \n",
    "            # Извлечение ссылок\n",
    "            links = soup.find_all(\"a\", href=True)\n",
    "            for link in links:\n",
    "                href = link['href'].strip()\n",
    "                text = link.get_text(strip=True)\n",
    "                full_url = urljoin(url, href)\n",
    "                data[\"links\"].append({\"text\": text, \"href\": full_url})\n",
    "            \n",
    "            # Сохранение данных в JSON (можно изменить режим на 'a' для добавления)\n",
    "            with open(\"page_data.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "            \n",
    "            # Проверка наличия '№ ' в ссылках\n",
    "            contains_num = False\n",
    "            for link in data['links']:\n",
    "                if link['text'][:2] == '№ ':\n",
    "                    filtered_data.append({'№': link['text'], 'link': link['href']})\n",
    "                    contains_num = True\n",
    "            \n",
    "            if contains_num:\n",
    "                # Создание DataFrame из отфильтрованных данных\n",
    "                df = pd.DataFrame(filtered_data, columns=['№', 'link'])\n",
    "                df['fz'] = fz\n",
    "                # Объединение с основным DataFrame\n",
    "                hdf = pd.concat([hdf, df], ignore_index=True)\n",
    "                # Очистка списка для следующей итерации\n",
    "                filtered_data = []\n",
    "            else:\n",
    "                print(f\"Страница {page} не содержит '№ ', прерываем цикл страниц для ключевого слова '{keyword}'.\")\n",
    "                break  # Прерываем цикл страниц, если '№ ' не найдено\n",
    "            \n",
    "            print(f\"Ключевое слово: {keyword}, Страница: {page}\")\n",
    "    \n",
    "        print(f\"Завершен обработка ключевого слова: {keyword}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ee8b63-884f-4fb0-bb5a-cf24bc57463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = hdf.drop_duplicates().reset_index(drop=True)\n",
    "n['fz'] = n['fz'].astype(int)\n",
    "n[['customer_inn','customer_kpp','name','publish_date','plan_year','start_date','phone','fio','okopf','link_attach','link_doc']] = None,None,None,None,None,None,None,None,None,None,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2bdd1a-81e1-4d00-b45f-ab22025afee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>№</th>\n",
       "      <th>link</th>\n",
       "      <th>fz</th>\n",
       "      <th>customer_inn</th>\n",
       "      <th>customer_kpp</th>\n",
       "      <th>name</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>plan_year</th>\n",
       "      <th>start_date</th>\n",
       "      <th>phone</th>\n",
       "      <th>fio</th>\n",
       "      <th>okopf</th>\n",
       "      <th>link_attach</th>\n",
       "      <th>link_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>№ 202508835000661002</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/ge...</td>\n",
       "      <td>44</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>№ 202503731000684001</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/ge...</td>\n",
       "      <td>44</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>№ 202508835000576001</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/ge...</td>\n",
       "      <td>44</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      №                                               link  \\\n",
       "0  № 202508835000661002  https://zakupki.gov.ru/epz/orderplan/pg2020/ge...   \n",
       "1  № 202503731000684001  https://zakupki.gov.ru/epz/orderplan/pg2020/ge...   \n",
       "2  № 202508835000576001  https://zakupki.gov.ru/epz/orderplan/pg2020/ge...   \n",
       "\n",
       "   fz customer_inn customer_kpp  name publish_date plan_year start_date phone  \\\n",
       "0  44         None         None  None         None      None       None  None   \n",
       "1  44         None         None  None         None      None       None  None   \n",
       "2  44         None         None  None         None      None       None  None   \n",
       "\n",
       "    fio okopf link_attach link_doc  \n",
       "0  None  None        None     None  \n",
       "1  None  None        None     None  \n",
       "2  None  None        None     None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2511ea-9da2-46f7-8413-5006ca5ef9b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in n.index:\n",
    "    print(i)\n",
    "    if n.loc[n.index==i]['fz'].values[0] == 44:\n",
    "        headers = {\"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\"AppleWebKit/537.36 (KHTML, like Gecko) \"\"Chrome/112.0.0.0 Safari/537.36\")}\n",
    "        url = n.loc[n.index==i]['link'].values[0]\n",
    "        response = requests.get(url, headers=headers)\n",
    "        try:\n",
    "            sleep_time = random.randint(1, 2)\n",
    "            time.sleep(sleep_time)\n",
    "            response = requests.get(url, headers=headers, timeout=4)\n",
    "            response.raise_for_status()  # Проверяет статус и вызывает исключение для ошибок HTTP\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Ошибка при запросе к {url}: {e}\")\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        clean = clean_text(soup.title.string) if soup.title else \"Без заголовка\"\n",
    "        extract = extract_text(soup)\n",
    "        links = extract_links(soup, url)\n",
    "        elements = extract_elements(soup)\n",
    "        \n",
    "        structured_data = {\"url\": url,\n",
    "                           \"title\": clean,\n",
    "                           \"full_text\": extract,\n",
    "                           \"links\": links,\n",
    "                           \"elements\": elements}\n",
    "        \n",
    "        data = json.loads(json.dumps(structured_data, ensure_ascii=False, indent=4))\n",
    "        n.loc[n.index==i,'customer_inn'] = get_next_element(data['full_text'], 'ИНН/КПП').split('/')[0]\n",
    "        n.loc[n.index==i,'customer_kpp'] = get_next_element(data['full_text'], 'ИНН/КПП').split('/')[1]\n",
    "        n.loc[n.index==i,'name'] = get_next_element(data['full_text'], 'Заказчик')\n",
    "        n.loc[n.index==i,'publish_date'] = get_next_element(data['full_text'], 'Дата размещения плана-графика закупок')\n",
    "        n.loc[n.index==i,'plan_year'] = get_next_element(data['full_text'], 'Финансовый год планирования')\n",
    "        n.loc[n.index==i,'start_date'] = get_next_element(data['full_text'], 'Плановый период')\n",
    "        n.loc[n.index==i,'phone'] = get_next_element(data['full_text'], 'Телефон')\n",
    "        n.loc[n.index==i,'fio'] = get_next_element(data['full_text'], 'ФИО лица, утвердившего план-график закупок')\n",
    "        n.loc[n.index==i,'okopf'] = get_next_element(data['full_text'], 'ОКОПФ')\n",
    "        for l in data['links']:\n",
    "            if l['text'] == 'Вложения':\n",
    "                n.loc[n.index==i,'link_attach'] = l['url']\n",
    "\n",
    "    if n.loc[n.index==i]['fz'].values[0] == 223:\n",
    "        headers = {\"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\"AppleWebKit/537.36 (KHTML, like Gecko) \"\"Chrome/112.0.0.0 Safari/537.36\")}\n",
    "        url = n.loc[n.index==i]['link'].values[0]\n",
    "        response = requests.get(url, headers=headers)\n",
    "        try:\n",
    "            sleep_time = random.randint(1, 2)\n",
    "            time.sleep(sleep_time)\n",
    "            response = requests.get(url, headers=headers, timeout=6)\n",
    "            response.raise_for_status()  # Проверяет статус и вызывает исключение для ошибок HTTP\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Ошибка при запросе к {url}: {e}\")\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        clean = clean_text(soup.title.string) if soup.title else \"Без заголовка\"\n",
    "        extract = extract_text(soup)\n",
    "        links = extract_links(soup, url)\n",
    "        elements = extract_elements(soup)\n",
    "        \n",
    "        structured_data = {\"url\": url,\n",
    "                           \"title\": clean,\n",
    "                           \"full_text\": extract,\n",
    "                           \"links\": links,\n",
    "                           \"elements\": elements}\n",
    "        \n",
    "        data = json.loads(json.dumps(structured_data, ensure_ascii=False, indent=4))\n",
    "        n.loc[n.index==i,'customer_inn'] = get_next_element(data['full_text'], 'ИНН')\n",
    "        n.loc[n.index==i,'customer_kpp'] = get_next_element(data['full_text'], 'КПП')\n",
    "        n.loc[n.index==i,'name'] = get_next_element(data['full_text'], 'Заказчик')\n",
    "        n.loc[n.index==i,'publish_date'] = get_next_element(data['full_text'], 'Размещено')\n",
    "        n.loc[n.index==i,'plan_year'] = get_next_element(data['full_text'], 'Период планирования')\n",
    "        n.loc[n.index==i,'start_date'] = get_next_element(data['full_text'], 'Период действия плана')\n",
    "        n.loc[n.index==i,'phone'] = get_next_element(data['full_text'], 'Телефон')\n",
    "        n.loc[n.index==i,'fio'] = get_next_element(data['full_text'], 'ФИО лица, утвердившего план-график закупок')\n",
    "        n.loc[n.index==i,'okopf'] = get_next_element(data['full_text'], 'ОКОПФ')\n",
    "\n",
    "        for l in data['links']:\n",
    "            if l['text'] == 'Документы':\n",
    "                n.loc[n.index==i,'link_attach'] = l['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29272880-7cdf-40c9-a74f-e702495b37b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a59b9e-c65f-4bf1-bbe9-43db174412b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = n[~n['customer_inn'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ab9987-0990-4014-a621-47bffb64a809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d679ccec-0f43-4130-b156-bd4a54ff4c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 0\n",
      "44 1\n",
      "44 2\n"
     ]
    }
   ],
   "source": [
    "fz_dict = {44:'https://zakupki.gov.ru/epz/orderplan/printForm/view.html?printFormId=',\n",
    "          223:'https://zakupki.gov.ru/223/plan/public/plan-info/print-form/show-with-paging.html?planInfoId='}\n",
    "for fz in [44,223]:\n",
    "    for i in n[n['fz']==fz].index:\n",
    "        print(fz,i)\n",
    "        headers = {\"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\"AppleWebKit/537.36 (KHTML, like Gecko) \"\"Chrome/112.0.0.0 Safari/537.36\")}\n",
    "        url = n.loc[n.index==i,'link_attach'].values[0]\n",
    "        response = requests.get(url, headers=headers)\n",
    "        try:\n",
    "            sleep_time = random.randint(1, 2)\n",
    "            time.sleep(sleep_time)\n",
    "            response = requests.get(url, headers=headers, timeout=8)\n",
    "            response.raise_for_status()  # Проверяет статус и вызывает исключение для ошибок HTTP\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Ошибка при запросе к {url}: {e}\")\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        clean = clean_text(soup.title.string) if soup.title else \"Без заголовка\"\n",
    "        extract = extract_text(soup)\n",
    "        links = extract_links(soup, url)\n",
    "        elements = extract_elements(soup)\n",
    "        structured_data = {\"url\": url,\"title\": clean,\"full_text\": extract,\"links\": links,\"elements\": elements}\n",
    "        data = json.loads(json.dumps(structured_data, ensure_ascii=False, indent=4))\n",
    "        for k in data['links']:\n",
    "            if (k['text'] == '') and (fz_dict[fz] in k['url']):\n",
    "                n.loc[n.index==i,'link_doc'] = k['url']\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d250139-de0d-4898-bd8d-976d079fbcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79172193-5bb6-43cd-825d-449ae70d15ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Парсинг страницы 1: https://zakupki.gov.ru/epz/orderplan/printForm/view.html?printFormId=78242312&source=pg2020PF&page=1\n",
      "Найдено таблиц на странице 1: 4\n",
      "Парсинг страницы 2: https://zakupki.gov.ru/epz/orderplan/printForm/view.html?printFormId=78242312&source=pg2020PF&page=2\n",
      "Повтор страницы. Останавливаем парсинг.\n",
      "Парсинг страницы 1: https://zakupki.gov.ru/epz/orderplan/printForm/view.html?printFormId=78175880&source=pg2020PF&page=1\n",
      "Найдено таблиц на странице 1: 4\n",
      "Парсинг страницы 2: https://zakupki.gov.ru/epz/orderplan/printForm/view.html?printFormId=78175880&source=pg2020PF&page=2\n",
      "Повтор страницы. Останавливаем парсинг.\n",
      "Парсинг страницы 1: https://zakupki.gov.ru/epz/orderplan/printForm/view.html?printFormId=78220527&source=pg2020PF&page=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79259\\AppData\\Local\\Temp\\ipykernel_27752\\875461464.py:123: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_pos = pd.concat([df,df_pos], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено таблиц на странице 1: 4\n",
      "Парсинг страницы 2: https://zakupki.gov.ru/epz/orderplan/printForm/view.html?printFormId=78220527&source=pg2020PF&page=2\n",
      "Повтор страницы. Останавливаем парсинг.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Функция для получения содержимого страницы\n",
    "def get_page_content(url, headers):\n",
    "    # Список интервалов ожидания в секундах (1 мин, 2 мин, 3 мин, 5 мин, 10, 15, 20, 25, 30 мин)\n",
    "    wait_times = [45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 114, 177, 258, 544, 901, 1208, 1444, 1782]\n",
    "    attempt = 0  # Номер текущей попытки\n",
    "\n",
    "    while attempt <= len(wait_times):\n",
    "        try:\n",
    "            # Случайная задержка перед запросом (2-4 секунды)\n",
    "            sleep_time = random.randint(2, 4)\n",
    "            time.sleep(sleep_time)\n",
    "            \n",
    "            # Выполнение GET-запроса\n",
    "            response = requests.get(url, headers=headers)\n",
    "            \n",
    "            # Проверка статуса ответа\n",
    "            if response.status_code == 200:\n",
    "                response.encoding = response.apparent_encoding\n",
    "                return response.text\n",
    "            else:\n",
    "                print(f\"Ошибка запроса {response.status_code} для URL: {url}\")\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Обработка исключений, связанных с запросом\n",
    "            print(f\"Исключение при запросе к {url}: {e}\")\n",
    "        \n",
    "        # Проверка, есть ли еще попытки\n",
    "        if attempt < len(wait_times):\n",
    "            wait = wait_times[attempt]\n",
    "            minutes = wait // 60\n",
    "            print(f\"Повторная попытка через {minutes} минут.\")\n",
    "            time.sleep(wait)  # Ожидание перед следующей попыткой\n",
    "            attempt += 1\n",
    "        else:\n",
    "            print(\"Максимальное количество попыток достигнуто. Запрос не удался.\")\n",
    "            return None\n",
    "\n",
    "df_pos = pd.DataFrame(columns = ['position_number','okpd2','okpd2_names','purchase_object','summ','data_notif','pos_start_date','type','link_doc'])\n",
    "\n",
    "for fz in [44,223]:\n",
    "    for i in n[n['fz']==fz].index:\n",
    "        base_url = n.loc[n.index==i]['link_doc'].values[0].split('&page')[0]+'&page={}' # Замените на реальный URL с пагинацией\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"}\n",
    "        all_rows = []\n",
    "        previous_page_content = None\n",
    "        page_number = 1\n",
    "        while True:\n",
    "            # Формируем URL для текущей страницы\n",
    "            url = base_url.format(page_number)\n",
    "            print(f\"Парсинг страницы {page_number}: {url}\")\n",
    "            \n",
    "            # Получаем содержимое страницы\n",
    "            page_content = get_page_content(url, headers)\n",
    "            if page_content is None:\n",
    "                break  # Если произошла ошибка запроса, выходим из цикла\n",
    "            \n",
    "            # Сравниваем текущую страницу с предыдущей\n",
    "            if page_content == previous_page_content:\n",
    "                print(\"Повтор страницы. Останавливаем парсинг.\")\n",
    "                break\n",
    "            \n",
    "            # Парсим содержимое текущей страницы\n",
    "            soup = BeautifulSoup(page_content, \"lxml\")\n",
    "            all_tables = soup.find_all(\"table\")\n",
    "            print(f\"Найдено таблиц на странице {page_number}: {len(all_tables)}\")\n",
    "            \n",
    "            # Если таблиц нет, пропускаем страницу\n",
    "            if not all_tables:\n",
    "                print(f\"Таблицы не найдены на странице {page_number}. Пропускаем.\")\n",
    "                page_number += 1\n",
    "                continue\n",
    "            if page_number>1:\n",
    "                df2 = df1.drop_duplicates().reset_index(drop=True).copy()\n",
    "            \n",
    "            # Обрабатываем таблицы\n",
    "            for idx, table in enumerate(all_tables):\n",
    "                rows = table.find_all(\"tr\")\n",
    "                for row in rows:\n",
    "                    cells = row.find_all([\"td\", \"th\"])\n",
    "                    row_text = [cell.get_text(strip=True) for cell in cells]\n",
    "                    # Добавляем идентификатор страницы и таблицы\n",
    "                    row_text.append(f\"Page_X\")\n",
    "                    #row_text.append(f\"Page_{page_number}\")\n",
    "                    row_text.append(f\"Table_{idx + 1}\")\n",
    "                    all_rows.append(row_text)\n",
    "\n",
    "            max_columns = max(len(row) for row in all_rows)\n",
    "            df1 = pd.DataFrame(all_rows, columns=[f\"Column_{i}\" for i in range(max_columns - 2)] + [\"Page_ID\", \"Table_ID\"])\n",
    "            df1 = df1.drop_duplicates().reset_index(drop=True)\n",
    "            if page_number>1:\n",
    "                if df1.shape == df2.shape:\n",
    "                    break\n",
    "            # Обновляем содержимое предыдущей страницы\n",
    "            previous_page_content = page_content\n",
    "            page_number += 1\n",
    "        \n",
    "        # Проверяем, есть ли собранные строки\n",
    "        if not all_rows:\n",
    "            print(\"Нет данных для создания DataFrame.\")\n",
    "        else:\n",
    "            # Преобразуем в DataFrame\n",
    "            max_columns = max(len(row) for row in all_rows)\n",
    "            columns = [f\"Column_{i}\" for i in range(max_columns - 2)] + [\"Page_ID\", \"Table_ID\"]\n",
    "            df = pd.DataFrame(all_rows, columns=columns)\n",
    "            if fz == 44:\n",
    "                df = df[(df['Column_5'].astype(str).apply(len)==4)&(df['Column_2'].astype(str).apply(len)>1)].dropna()\n",
    "                df['Column_6'] = pd.to_numeric(df['Column_6'], errors=\"coerce\").fillna(0)\n",
    "                df = df[df['Column_6']>500000]\n",
    "                df = df[['Column_1','Column_2','Column_3','Column_4','Column_6','Column_5']].drop_duplicates()\n",
    "                df['pos_start_date'] = None\n",
    "                df['type'] = None\n",
    "                df['link_doc'] = n.loc[n.index==i]['link_doc'].values[0]\n",
    "                df.columns = ['position_number','okpd2','okpd2_names','purchase_object','summ','data_notif','pos_start_date','type','link_doc']\n",
    "            if fz == 223:\n",
    "                df = df[df['Column_14'].isin(['Да','Нет'])]\n",
    "                df = df[['Column_0','Column_2','Column_1','Column_3','Column_10','Column_11','Column_12','Column_13']]\n",
    "                df['link_doc'] = n.loc[n.index==i]['link_doc'].values[0]\n",
    "                df.columns = ['position_number','okpd2','okpd2_names','purchase_object','summ','data_notif','pos_start_date','type','link_doc']\n",
    "            df_pos = pd.concat([df,df_pos], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2853bd6a-6f97-4ed6-ba1e-8c6a4fd8d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = n.merge(df_pos,on='link_doc',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6803bc62-3132-4c5f-9c9b-3f2bffdb87b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = t1[t1['okpd2'].astype(str).str.startswith('77')|t1['okpd2'].astype(str).str.startswith('64')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8659e47f-c31c-49c3-8c66-26e788359c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>№</th>\n",
       "      <th>link</th>\n",
       "      <th>fz</th>\n",
       "      <th>customer_inn</th>\n",
       "      <th>customer_kpp</th>\n",
       "      <th>name</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>plan_year</th>\n",
       "      <th>start_date</th>\n",
       "      <th>phone</th>\n",
       "      <th>...</th>\n",
       "      <th>link_attach</th>\n",
       "      <th>link_doc</th>\n",
       "      <th>position_number</th>\n",
       "      <th>okpd2</th>\n",
       "      <th>okpd2_names</th>\n",
       "      <th>purchase_object</th>\n",
       "      <th>summ</th>\n",
       "      <th>data_notif</th>\n",
       "      <th>pos_start_date</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>№ 202503731000684001</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/ge...</td>\n",
       "      <td>44</td>\n",
       "      <td>7703255580</td>\n",
       "      <td>770301001</td>\n",
       "      <td>ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...</td>\n",
       "      <td>29.01.2025</td>\n",
       "      <td>2025 (2026 – 2027 года)</td>\n",
       "      <td>2026 - 2027</td>\n",
       "      <td>7-499-2544387</td>\n",
       "      <td>...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/do...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/printForm...</td>\n",
       "      <td>251770325558077030100100320007729244</td>\n",
       "      <td>77.29.19.000</td>\n",
       "      <td>Услуги по прокату прочих бытовых изделий и пре...</td>\n",
       "      <td>Аренда и обслуживание напольных покрытий</td>\n",
       "      <td>555010.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>№ 202503731000684001</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/ge...</td>\n",
       "      <td>44</td>\n",
       "      <td>7703255580</td>\n",
       "      <td>770301001</td>\n",
       "      <td>ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...</td>\n",
       "      <td>29.01.2025</td>\n",
       "      <td>2025 (2026 – 2027 года)</td>\n",
       "      <td>2026 - 2027</td>\n",
       "      <td>7-499-2544387</td>\n",
       "      <td>...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/do...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/printForm...</td>\n",
       "      <td>261770325558077030100100250007729244</td>\n",
       "      <td>77.29.19.000</td>\n",
       "      <td>Услуги по прокату прочих бытовых изделий и пре...</td>\n",
       "      <td>Аренда и обслуживание напольных покрытий</td>\n",
       "      <td>577210.0</td>\n",
       "      <td>2026</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      №                                               link  \\\n",
       "0  № 202503731000684001  https://zakupki.gov.ru/epz/orderplan/pg2020/ge...   \n",
       "1  № 202503731000684001  https://zakupki.gov.ru/epz/orderplan/pg2020/ge...   \n",
       "\n",
       "   fz customer_inn customer_kpp  \\\n",
       "0  44   7703255580    770301001   \n",
       "1  44   7703255580    770301001   \n",
       "\n",
       "                                                name publish_date  \\\n",
       "0  ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...   29.01.2025   \n",
       "1  ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...   29.01.2025   \n",
       "\n",
       "                 plan_year   start_date          phone  ...  \\\n",
       "0  2025 (2026 – 2027 года)  2026 - 2027  7-499-2544387  ...   \n",
       "1  2025 (2026 – 2027 года)  2026 - 2027  7-499-2544387  ...   \n",
       "\n",
       "                                         link_attach  \\\n",
       "0  https://zakupki.gov.ru/epz/orderplan/pg2020/do...   \n",
       "1  https://zakupki.gov.ru/epz/orderplan/pg2020/do...   \n",
       "\n",
       "                                            link_doc  \\\n",
       "0  https://zakupki.gov.ru/epz/orderplan/printForm...   \n",
       "1  https://zakupki.gov.ru/epz/orderplan/printForm...   \n",
       "\n",
       "                        position_number         okpd2  \\\n",
       "0  251770325558077030100100320007729244  77.29.19.000   \n",
       "1  261770325558077030100100250007729244  77.29.19.000   \n",
       "\n",
       "                                         okpd2_names  \\\n",
       "0  Услуги по прокату прочих бытовых изделий и пре...   \n",
       "1  Услуги по прокату прочих бытовых изделий и пре...   \n",
       "\n",
       "                            purchase_object      summ data_notif  \\\n",
       "0  Аренда и обслуживание напольных покрытий  555010.0       2025   \n",
       "1  Аренда и обслуживание напольных покрытий  577210.0       2026   \n",
       "\n",
       "   pos_start_date  type  \n",
       "0            None  None  \n",
       "1            None  None  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc958e8d-e01a-4141-8f85-93b9cc1284f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>№</th>\n",
       "      <th>link</th>\n",
       "      <th>fz</th>\n",
       "      <th>customer_inn</th>\n",
       "      <th>customer_kpp</th>\n",
       "      <th>name</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>plan_year</th>\n",
       "      <th>start_date</th>\n",
       "      <th>phone</th>\n",
       "      <th>...</th>\n",
       "      <th>link_attach</th>\n",
       "      <th>link_doc</th>\n",
       "      <th>position_number</th>\n",
       "      <th>okpd2</th>\n",
       "      <th>okpd2_names</th>\n",
       "      <th>purchase_object</th>\n",
       "      <th>summ</th>\n",
       "      <th>data_notif</th>\n",
       "      <th>pos_start_date</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>№ 202503731000684001</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/ge...</td>\n",
       "      <td>44</td>\n",
       "      <td>7703255580</td>\n",
       "      <td>770301001</td>\n",
       "      <td>ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...</td>\n",
       "      <td>29.01.2025</td>\n",
       "      <td>2025 (2026 – 2027 года)</td>\n",
       "      <td>2026 - 2027</td>\n",
       "      <td>7-499-2544387</td>\n",
       "      <td>...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/do...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/printForm...</td>\n",
       "      <td>251770325558077030100100320007729244</td>\n",
       "      <td>77.29.19.000</td>\n",
       "      <td>Услуги по прокату прочих бытовых изделий и пре...</td>\n",
       "      <td>Аренда и обслуживание напольных покрытий</td>\n",
       "      <td>555010.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>№ 202503731000684001</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/ge...</td>\n",
       "      <td>44</td>\n",
       "      <td>7703255580</td>\n",
       "      <td>770301001</td>\n",
       "      <td>ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...</td>\n",
       "      <td>29.01.2025</td>\n",
       "      <td>2025 (2026 – 2027 года)</td>\n",
       "      <td>2026 - 2027</td>\n",
       "      <td>7-499-2544387</td>\n",
       "      <td>...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/do...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/printForm...</td>\n",
       "      <td>261770325558077030100100250007729244</td>\n",
       "      <td>77.29.19.000</td>\n",
       "      <td>Услуги по прокату прочих бытовых изделий и пре...</td>\n",
       "      <td>Аренда и обслуживание напольных покрытий</td>\n",
       "      <td>577210.0</td>\n",
       "      <td>2026</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      №                                               link  \\\n",
       "0  № 202503731000684001  https://zakupki.gov.ru/epz/orderplan/pg2020/ge...   \n",
       "1  № 202503731000684001  https://zakupki.gov.ru/epz/orderplan/pg2020/ge...   \n",
       "\n",
       "   fz customer_inn customer_kpp  \\\n",
       "0  44   7703255580    770301001   \n",
       "1  44   7703255580    770301001   \n",
       "\n",
       "                                                name publish_date  \\\n",
       "0  ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...   29.01.2025   \n",
       "1  ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...   29.01.2025   \n",
       "\n",
       "                 plan_year   start_date          phone  ...  \\\n",
       "0  2025 (2026 – 2027 года)  2026 - 2027  7-499-2544387  ...   \n",
       "1  2025 (2026 – 2027 года)  2026 - 2027  7-499-2544387  ...   \n",
       "\n",
       "                                         link_attach  \\\n",
       "0  https://zakupki.gov.ru/epz/orderplan/pg2020/do...   \n",
       "1  https://zakupki.gov.ru/epz/orderplan/pg2020/do...   \n",
       "\n",
       "                                            link_doc  \\\n",
       "0  https://zakupki.gov.ru/epz/orderplan/printForm...   \n",
       "1  https://zakupki.gov.ru/epz/orderplan/printForm...   \n",
       "\n",
       "                        position_number         okpd2  \\\n",
       "0  251770325558077030100100320007729244  77.29.19.000   \n",
       "1  261770325558077030100100250007729244  77.29.19.000   \n",
       "\n",
       "                                         okpd2_names  \\\n",
       "0  Услуги по прокату прочих бытовых изделий и пре...   \n",
       "1  Услуги по прокату прочих бытовых изделий и пре...   \n",
       "\n",
       "                            purchase_object      summ data_notif  \\\n",
       "0  Аренда и обслуживание напольных покрытий  555010.0       2025   \n",
       "1  Аренда и обслуживание напольных покрытий  577210.0       2026   \n",
       "\n",
       "   pos_start_date  type  \n",
       "0            None  None  \n",
       "1            None  None  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "569827e3-758e-4d1d-91bf-3cd9c7850411",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.to_excel('plan-gr_30.01.2025.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8b87974-29d6-4cbd-8cb8-5dec4e8f7748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>№</th>\n",
       "      <th>link</th>\n",
       "      <th>fz</th>\n",
       "      <th>customer_inn</th>\n",
       "      <th>customer_kpp</th>\n",
       "      <th>name</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>plan_year</th>\n",
       "      <th>start_date</th>\n",
       "      <th>phone</th>\n",
       "      <th>...</th>\n",
       "      <th>link_attach</th>\n",
       "      <th>link_doc</th>\n",
       "      <th>position_number</th>\n",
       "      <th>okpd2</th>\n",
       "      <th>okpd2_names</th>\n",
       "      <th>purchase_object</th>\n",
       "      <th>summ</th>\n",
       "      <th>data_notif</th>\n",
       "      <th>pos_start_date</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>№ 202503731000684001</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/ge...</td>\n",
       "      <td>44</td>\n",
       "      <td>7703255580</td>\n",
       "      <td>770301001</td>\n",
       "      <td>ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...</td>\n",
       "      <td>29.01.2025</td>\n",
       "      <td>2025 (2026 – 2027 года)</td>\n",
       "      <td>2026 - 2027</td>\n",
       "      <td>7-499-2544387</td>\n",
       "      <td>...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/do...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/printForm...</td>\n",
       "      <td>251770325558077030100100320007729244</td>\n",
       "      <td>77.29.19.000</td>\n",
       "      <td>Услуги по прокату прочих бытовых изделий и пре...</td>\n",
       "      <td>Аренда и обслуживание напольных покрытий</td>\n",
       "      <td>555010.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>№ 202503731000684001</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/ge...</td>\n",
       "      <td>44</td>\n",
       "      <td>7703255580</td>\n",
       "      <td>770301001</td>\n",
       "      <td>ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...</td>\n",
       "      <td>29.01.2025</td>\n",
       "      <td>2025 (2026 – 2027 года)</td>\n",
       "      <td>2026 - 2027</td>\n",
       "      <td>7-499-2544387</td>\n",
       "      <td>...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/pg2020/do...</td>\n",
       "      <td>https://zakupki.gov.ru/epz/orderplan/printForm...</td>\n",
       "      <td>261770325558077030100100250007729244</td>\n",
       "      <td>77.29.19.000</td>\n",
       "      <td>Услуги по прокату прочих бытовых изделий и пре...</td>\n",
       "      <td>Аренда и обслуживание напольных покрытий</td>\n",
       "      <td>577210.0</td>\n",
       "      <td>2026</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      №                                               link  \\\n",
       "0  № 202503731000684001  https://zakupki.gov.ru/epz/orderplan/pg2020/ge...   \n",
       "1  № 202503731000684001  https://zakupki.gov.ru/epz/orderplan/pg2020/ge...   \n",
       "\n",
       "   fz customer_inn customer_kpp  \\\n",
       "0  44   7703255580    770301001   \n",
       "1  44   7703255580    770301001   \n",
       "\n",
       "                                                name publish_date  \\\n",
       "0  ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...   29.01.2025   \n",
       "1  ФЕДЕРАЛЬНОЕ КАЗЕННОЕ УЧРЕЖДЕНИЕ \"ДИРЕКЦИЯ ПО О...   29.01.2025   \n",
       "\n",
       "                 plan_year   start_date          phone  ...  \\\n",
       "0  2025 (2026 – 2027 года)  2026 - 2027  7-499-2544387  ...   \n",
       "1  2025 (2026 – 2027 года)  2026 - 2027  7-499-2544387  ...   \n",
       "\n",
       "                                         link_attach  \\\n",
       "0  https://zakupki.gov.ru/epz/orderplan/pg2020/do...   \n",
       "1  https://zakupki.gov.ru/epz/orderplan/pg2020/do...   \n",
       "\n",
       "                                            link_doc  \\\n",
       "0  https://zakupki.gov.ru/epz/orderplan/printForm...   \n",
       "1  https://zakupki.gov.ru/epz/orderplan/printForm...   \n",
       "\n",
       "                        position_number         okpd2  \\\n",
       "0  251770325558077030100100320007729244  77.29.19.000   \n",
       "1  261770325558077030100100250007729244  77.29.19.000   \n",
       "\n",
       "                                         okpd2_names  \\\n",
       "0  Услуги по прокату прочих бытовых изделий и пре...   \n",
       "1  Услуги по прокату прочих бытовых изделий и пре...   \n",
       "\n",
       "                            purchase_object      summ data_notif  \\\n",
       "0  Аренда и обслуживание напольных покрытий  555010.0       2025   \n",
       "1  Аренда и обслуживание напольных покрытий  577210.0       2026   \n",
       "\n",
       "   pos_start_date  type  \n",
       "0            None  None  \n",
       "1            None  None  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f97d36-e1df-4837-a81a-0af258a00d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c783853-4567-4749-ad5c-a986aea09762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e3455-6055-482c-8efe-ad12229a98dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ee4f8-71db-4f3c-a68d-0a544a0e904e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0905b-4713-40a8-8567-9b120ca4ab6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f01f7c-b83d-4e34-b39a-1dae84ddf9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a9fd3-f3a9-47f6-92ff-c34ebe1dc267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d33359-1983-415d-8340-382bec8925ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c2116-1dd0-47af-8db4-5cea7a9f4639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95a2c0-f11a-450d-8cc6-3fedd065d8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a89be-388d-4085-98db-e0d2686a6767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pos.to_excel('df_pos.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7c31b-9c97-4568-abe8-82f4b3b7af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(df_pos[1467:1468]['summ'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce3b779-222b-4c4b-8eb9-51b213c8930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = n.merge(df_pos,on='link_doc',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4f436-39ca-4c1d-9aed-3f6dc935611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54c356-7cfa-481d-b467-dccb6a939c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = t1[t1['okpd2'].astype(str).str.startswith('77')|t1['okpd2'].astype(str).str.startswith('64')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b5c81-ece9-4034-98df-c71af1ab5a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09abe2a0-ceb7-418b-a4fa-aa2d2f361d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead992e-77e2-4f22-960c-cef023af2d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5310bd14-3d3b-400a-a704-291ad74b5670",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.to_excel('t1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ce695-e9a3-4188-a5a8-ca2b0beea240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Функция для получения содержимого страницы\n",
    "def get_page_content(url, headers):\n",
    "    sleep_time = random.randint(2, 4)\n",
    "    time.sleep(sleep_time)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Ошибка запроса {response.status_code} для URL: {url}\")\n",
    "        return None\n",
    "    response.encoding = response.apparent_encoding\n",
    "    return response.text\n",
    "\n",
    "# Указанные параметры\n",
    "#doc_url = n['link_doc'].values[0].split('&page')[0]+'&page={}\"\n",
    "base_url = n['link_doc'].values[-1].split('&page')[0]+'&page={}' # Замените на реальный URL с пагинацией\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Список для хранения всех строк всех таблиц\n",
    "all_rows = []\n",
    "\n",
    "# Переменные для трекинга страниц\n",
    "previous_page_content = None\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    # Формируем URL для текущей страницы\n",
    "    url = base_url.format(page_number)\n",
    "    print(f\"Парсинг страницы {page_number}: {url}\")\n",
    "    \n",
    "    # Получаем содержимое страницы\n",
    "    page_content = get_page_content(url, headers)\n",
    "    if page_content is None:\n",
    "        break  # Если произошла ошибка запроса, выходим из цикла\n",
    "    \n",
    "    # Сравниваем текущую страницу с предыдущей\n",
    "    if page_content == previous_page_content:\n",
    "        print(\"Повтор страницы. Останавливаем парсинг.\")\n",
    "        break\n",
    "    \n",
    "    # Парсим содержимое текущей страницы\n",
    "    soup = BeautifulSoup(page_content, \"lxml\")\n",
    "    all_tables = soup.find_all(\"table\")\n",
    "    print(f\"Найдено таблиц на странице {page_number}: {len(all_tables)}\")\n",
    "    \n",
    "    # Если таблиц нет, пропускаем страницу\n",
    "    if not all_tables:\n",
    "        print(f\"Таблицы не найдены на странице {page_number}. Пропускаем.\")\n",
    "        page_number += 1\n",
    "        continue\n",
    "    \n",
    "    # Обрабатываем таблицы\n",
    "    for idx, table in enumerate(all_tables):\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            cells = row.find_all([\"td\", \"th\"])\n",
    "            row_text = [cell.get_text(strip=True) for cell in cells]\n",
    "            # Добавляем идентификатор страницы и таблицы\n",
    "            row_text.append(f\"Page_{page_number}\")\n",
    "            row_text.append(f\"Table_{idx + 1}\")\n",
    "            all_rows.append(row_text)\n",
    "    \n",
    "    # Обновляем содержимое предыдущей страницы\n",
    "    previous_page_content = page_content\n",
    "    page_number += 1\n",
    "\n",
    "# Проверяем, есть ли собранные строки\n",
    "if not all_rows:\n",
    "    print(\"Нет данных для создания DataFrame.\")\n",
    "else:\n",
    "    # Преобразуем в DataFrame\n",
    "    max_columns = max(len(row) for row in all_rows)\n",
    "    columns = [f\"Column_{i}\" for i in range(max_columns - 2)] + [\"Page_ID\", \"Table_ID\"]\n",
    "    df = pd.DataFrame(all_rows, columns=columns)\n",
    "    df = df[df['Column_14'].isin(['Да','Нет'])]\n",
    "    df = df[['Column_0','Column_2','Column_1','Column_3','Column_10','Column_11','Column_12','Column_13']]\n",
    "    df['link_doc'] = n['link_doc'].values[-1]\n",
    "    df.columns = ['position_number','okpd2','okpd2_names','purchase_object','summ','data_notif','pos_start_date','type','link_doc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db311c-17f9-437f-b08f-b81142cf7823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d16da-aec4-4fc3-8200-e4a176db1c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27972d76-fe1c-4c14-ad38-1726b5d9e39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe92262-fe59-4eaf-934d-03d4bd28a42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce5af3-9089-47e1-8223-b5d052bd3069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b6d6d6-77dd-4e3f-b977-5addcd2e240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db523e47-ea7e-4712-88dc-9d046a1d0e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = n['link_doc'].values[0]\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "resp = requests.get(url)\n",
    "resp.encoding = resp.apparent_encoding\n",
    "\n",
    "soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "# Найдём все таблицы\n",
    "all_tables = soup.find_all(\"table\")\n",
    "print(\"Всего таблиц:\", len(all_tables))\n",
    "\n",
    "# Допустим, большая таблица - это последняя (или нам видно, что это 4-я по счёту)\n",
    "table = all_tables[-1]  # Или all_tables[3], если вручную определили индекс\n",
    "\n",
    "# Берём thead (если есть) и tbody (если есть)\n",
    "thead = table.find(\"thead\")\n",
    "tbody = table.find(\"tbody\")\n",
    "\n",
    "# Примерный алгоритм: собрать заголовки <th> или первую <tr> как имена столбцов\n",
    "headers = []\n",
    "if thead:\n",
    "    # Иногда нужные заголовки лежат в нескольких tr. Или вы берёте просто первую строку\n",
    "    header_rows = thead.find_all(\"tr\")\n",
    "    # В простейшем случае, берем последнюю строку thead (часто в ней реальные названия)\n",
    "    last_header_row = header_rows[-1]\n",
    "    for cell in last_header_row.find_all([\"th\", \"td\"]):\n",
    "        headers.append(cell.get_text(strip=True))\n",
    "else:\n",
    "    # Если thead нет, берем первую строчку tbody в качестве заголовков\n",
    "    first_row = table.find(\"tr\")\n",
    "    for cell in first_row.find_all([\"th\", \"td\"]):\n",
    "        headers.append(cell.get_text(strip=True))\n",
    "\n",
    "print(\"Заголовки:\", headers)\n",
    "\n",
    "# Далее строки данных\n",
    "rows_data = []\n",
    "for row in tbody.find_all(\"tr\"):\n",
    "    cells = row.find_all([\"td\", \"th\"])\n",
    "    row_text = [c.get_text(strip=True) for c in cells]\n",
    "    rows_data.append(row_text)\n",
    "\n",
    "# Теперь можно собрать всё в pandas.DataFrame:\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(rows_data, columns=headers)\n",
    "df[df['3'].apply(len)>1].dropna()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55fb31e-f548-4a2a-9623-7b1af34ef12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f365d8a4-46cf-4522-8f1c-82a3ae041a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['3'].apply(len)>1].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a91e9-1aeb-4f47-9b42-e432791aca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7c020-0051-49b4-b37e-e592a3dd586e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Исходный список данных\n",
    "data_list = data['full_text']\n",
    "\n",
    "# Регулярные выражения\n",
    "pattern_okpd2 = re.compile(r'\\d+\\.\\d+:')\n",
    "pattern_price = re.compile(r'.*,\\d{2}$')\n",
    "\n",
    "# Разбивка списка на блоки по 4 элемента\n",
    "blocks = [data_list[i:i + 4] for i in range(0, len(data_list), 4)]\n",
    "\n",
    "matched_blocks = []\n",
    "\n",
    "for block in blocks:\n",
    "    if len(block) == 4:\n",
    "        code, purchase_item, okpd2, price = block\n",
    "        if pattern_okpd2.search(okpd2) and pattern_price.search(price):\n",
    "            matched_blocks.append({\n",
    "                'Код закупки': code,\n",
    "                'Предмет закупки': purchase_item,\n",
    "                'ОКПД2': okpd2,\n",
    "                'Цена': price\n",
    "            })\n",
    "    else:\n",
    "        print(f\"Неполный блок: {block}\")\n",
    "\n",
    "# Вывод результатов\n",
    "for block in matched_blocks:\n",
    "    print(\"Код закупки:\", block['Код закупки'])\n",
    "    print(\"Предмет закупки:\", block['Предмет закупки'])\n",
    "    print(\"ОКПД2:\", block['ОКПД2'])\n",
    "    print(\"Цена:\", block['Цена'])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0cbdf7-a7f4-4ffe-b50d-e826377b0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d8ba8-e1cd-48d4-912c-d483990147e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b61ccd-b0ef-4192-8fbe-68475b621510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# URL первой страницы\n",
    "base_url = 'https://zakupki.gov.ru/epz/orderplan/pg2020/plan-position.html?plan-number=202503873000018001&revision-id=&position-number='  # Замените на нужный URL\n",
    "\n",
    "# Заголовки для имитации браузера\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
    "}\n",
    "\n",
    "# Таймаут в секундах\n",
    "REQUEST_TIMEOUT = 10  # Можно настроить в зависимости от ваших потребностей\n",
    "\n",
    "# Количество попыток при возникновении ошибок\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# Задержка между попытками (в секундах)\n",
    "RETRY_DELAY = 5\n",
    "\n",
    "# Функция для получения BeautifulSoup объекта с обработкой таймаута и ошибок\n",
    "def get_soup(url):\n",
    "    attempts = 0\n",
    "    while attempts < MAX_RETRIES:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)\n",
    "            response.raise_for_status()  # Проверка на HTTP ошибки\n",
    "            return BeautifulSoup(response.text, 'html.parser')\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"Таймаут при запросе {url}. Попытка {attempts + 1} из {MAX_RETRIES}.\")\n",
    "        except requests.exceptions.HTTPError as http_err:\n",
    "            print(f\"HTTP ошибка при запросе {url}: {http_err}\")\n",
    "            break  # Не имеет смысла повторять запрос при HTTP ошибках\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(f\"Ошибка при запросе {url}: {err}\")\n",
    "            break\n",
    "        attempts += 1\n",
    "        time.sleep(RETRY_DELAY)\n",
    "    print(f\"Не удалось получить страницу {url} после {MAX_RETRIES} попыток.\")\n",
    "    return None\n",
    "\n",
    "# Функция для поиска ссылки на вторую страницу\n",
    "def find_second_page_url(soup, current_url):\n",
    "    # Попытка найти ссылку с текстом \"2\"\n",
    "    second_page_link = soup.find('a', text='2')\n",
    "    if not second_page_link:\n",
    "        # Альтернативный способ: поиск внутри контейнера пагинации\n",
    "        pagination = soup.find('div', class_='pagination')\n",
    "        if pagination:\n",
    "            second_page_link = pagination.find('a', text='2')\n",
    "    \n",
    "    if second_page_link:\n",
    "        href = second_page_link.get('href')\n",
    "        # Проверка на относительную ссылку\n",
    "        second_page_url = urljoin(current_url, href)\n",
    "        return second_page_url\n",
    "    return None\n",
    "\n",
    "# Получаем первую страницу\n",
    "soup = get_soup(base_url)\n",
    "if soup is None:\n",
    "    exit()\n",
    "\n",
    "# Ищем ссылку на вторую страницу\n",
    "second_page_url = find_second_page_url(soup, base_url)\n",
    "if second_page_url:\n",
    "    print(f\"Ссылка на вторую страницу: {second_page_url}\")\n",
    "    \n",
    "    # Получаем вторую страницу с обработкой таймаута\n",
    "    soup_second = get_soup(second_page_url)\n",
    "    if soup_second:\n",
    "        print(\"Вторая страница успешно загружена.\")\n",
    "        # Пример обработки содержимого второй страницы\n",
    "        # Например, вывод заголовков статей\n",
    "        articles = soup_second.find_all('h2', class_='article-title')\n",
    "        for idx, article in enumerate(articles, start=1):\n",
    "            print(f\"{idx}. {article.get_text(strip=True)}\")\n",
    "    else:\n",
    "        print(\"Не удалось загрузить вторую страницу.\")\n",
    "else:\n",
    "    print(\"Ссылка на вторую страницу не найдена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d2265-8ac4-4658-b6b4-534940f88377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae335270-e0aa-44c6-9898-dfa20b7133e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e59cc-aa27-41ef-9a67-0ef0fabce9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab550c6-4589-4f81-8544-4d69a85c7562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2fedd0-5208-4e0f-8f48-1967ee810a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cee50-97a7-4b42-9ee1-03eeaced0a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7916cd3-63b7-4f3b-9b41-01ab37f74916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ab178-3f6b-4d71-9ebe-3093b0bc3d51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for l in data['links']:\n",
    "    if l['text'] == 'Позиции плана закупки':\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d48f0f7-849c-456f-95bd-ebabfc2fac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\"AppleWebKit/537.36 (KHTML, like Gecko) \"\"Chrome/112.0.0.0 Safari/537.36\")}\n",
    "url = n.loc[n.index==0]['link'].values[0]\n",
    "response = requests.get(url, headers=headers)\n",
    "try:\n",
    "    response = requests.get(url, headers=headers, timeout=10)\n",
    "    response.raise_for_status()  # Проверяет статус и вызывает исключение для ошибок HTTP\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Ошибка при запросе к {url}: {e}\")\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "clean = clean_text(soup.title.string) if soup.title else \"Без заголовка\"\n",
    "extract = extract_text(soup)\n",
    "links = extract_links(soup, url)\n",
    "elements = extract_elements(soup)\n",
    "\n",
    "structured_data = {\"url\": url,\n",
    "                   \"title\": clean,\n",
    "                   \"full_text\": extract,\n",
    "                   \"links\": links,\n",
    "                   \"elements\": elements}\n",
    "\n",
    "json_output = json.dumps(structured_data, ensure_ascii=False, indent=4)\n",
    "with open(\"structured_data.json\", \"w\", encoding=\"utf-8\") as f: f.write(json_output)\n",
    "with open(\"structured_data.json\", \"r\", encoding=\"utf-8\") as file: data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f974aa3-5e5d-43ee-9fa6-6d2c3ebebc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee059c8-1291-4374-9bd1-c3f235c865ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next_element(data['full_text'], 'ИНН')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ad95b-fbb4-4f98-abb4-04b352305bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.loc[n.index==i,'customer_inn'] = get_next_element(data['full_text'], 'ИНН').split('/')[0]\n",
    "n.loc[n.index==i,'customer_kpp'] = get_next_element(data['full_text'], 'КПП').split('/')[1]\n",
    "n.loc[n.index==i,'name'] = get_next_element(data['full_text'], 'Заказчик')\n",
    "n.loc[n.index==i,'publish_date'] = get_next_element(data['full_text'], 'Размещено')\n",
    "n.loc[n.index==i,'plan_year'] = get_next_element(data['full_text'], 'Период планирования')\n",
    "n.loc[n.index==i,'start_date'] = get_next_element(data['full_text'], 'Период действия плана')\n",
    "n.loc[n.index==i,'phone'] = get_next_element(data['full_text'], 'Телефон')\n",
    "n.loc[n.index==i,'fio'] = get_next_element(data['full_text'], 'ФИО лица, утвердившего план-график закупок')\n",
    "n.loc[n.index==i,'okopf'] = get_next_element(data['full_text'], 'ОКОПФ')\n",
    "n.loc[n.index==i,'start_date'] = get_next_element(data['full_text'], 'Период действия плана')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1364299e-163c-4d6f-8296-043b73fe4e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f1c42-8beb-43c1-9267-5861ba7bf681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e692907d-a0d7-4205-988a-bf45584223b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed36a84-d590-4fa9-9a9f-bb97657a729e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0640d0-c574-4454-aa87-ece5b599d0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5f4d03-4e82-443a-beb5-6c7af815cf15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Открываем файл JSON\n",
    "with open(\"page_data.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Пример работы с данными\n",
    "print(\"URL страницы:\", data[\"url\"])\n",
    "print(\"Текст страницы:\")\n",
    "print(data[\"page_text\"])\n",
    "\n",
    "print(\"\\nСсылки:\")\n",
    "for link in data[\"links\"]:\n",
    "    print(f\"Текст: {link['text']} | Ссылка: {link['href']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe079573-4e15-4777-a983-fe7e6c6a320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filtered_data = []\n",
    "\n",
    "for k in data['links']:\n",
    "    if '№ ' in k['text']:\n",
    "        filtered_data.append({'№': k['text'], 'link': k['href']})\n",
    "\n",
    "df = pd.DataFrame(filtered_data, columns=['№', 'link'])\n",
    "df = pd.DataFrame([{'№': k['text'], 'link': k['href']} for k in data['links'] if '№ ' in k['text']],columns=['№', 'link'])\n",
    "all_links_df = pd.DataFrame(data['links'])\n",
    "df = all_links_df[all_links_df['text'].str.contains('№ ')][['text', 'href']].rename(columns={'text': '№', 'href': 'link'})\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9322e-f0ff-4399-ab4a-9093003ebc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if '№ ' in k and 'purchase-plan' in str(v):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
